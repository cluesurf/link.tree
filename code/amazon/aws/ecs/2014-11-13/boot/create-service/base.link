
load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/access-denied-exception
  take form access-denied-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/client-exception
  take form client-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/cluster-not-found-exception
  take form cluster-not-found-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/create-service-response
  take form create-service-response

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/invalid-parameter-exception
  take form invalid-parameter-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/platform-task-definition-incompatibility-exception
  take form platform-task-definition-incompatibility-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/platform-unknown-exception
  take form platform-unknown-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/server-exception
  take form server-exception

load @termsurf/snow/amazonaws.com/ecs/2014-11-13/base/unsupported-feature-exception
  take form unsupported-feature-exception

load @termsurf/snow/base/native-string
  take form native-string

boot create-service, name <CreateService>
  deed post
  note <Runs and maintains a desired number of tasks from a specified task definition. If the number of tasks running in a service drops below the `desiredCount`, Amazon ECS runs another copy of the task in the specified cluster. To update an existing service, see the UpdateService action.

In addition to maintaining the desired count of tasks in your service, you can optionally run your service behind one or more load balancers. The load balancers distribute traffic across the tasks that are associated with the service. For more information, see [Service Load Balancing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-load-balancing.html) in the _Amazon Elastic Container Service Developer Guide_.

Tasks for services that _do not_ use a load balancer are considered healthy if they're in the `RUNNING` state. Tasks for services that _do_ use a load balancer are considered healthy if they're in the `RUNNING` state and the container instance that they're hosted on is reported as healthy by the load balancer.

There are two service scheduler strategies available:

- `REPLICA` - The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions. For more information, see [Service Scheduler Concepts](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html) in the _Amazon Elastic Container Service Developer Guide_.

- `DAEMON` - The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints. When using this strategy, you don't need to specify a desired number of tasks, a task placement strategy, or use Service Auto Scaling policies. For more information, see [Service Scheduler Concepts](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html) in the _Amazon Elastic Container Service Developer Guide_.

You can optionally specify a deployment configuration for your service. The deployment is triggered by changing properties, such as the task definition or the desired count of a service, with an UpdateService operation. The default value for a replica service for `minimumHealthyPercent` is 100%. The default value for a daemon service for `minimumHealthyPercent` is 0%.

If a service is using the `ECS` deployment controller, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the `RUNNING` state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the `DRAINING` state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler might stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that _do not_ use a load balancer are considered healthy if they're in the `RUNNING` state. Tasks for services that _do_ use a load balancer are considered healthy if they're in the `RUNNING` state and they're reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.

If a service is using the `ECS` deployment controller, the **maximum percent** parameter represents an upper limit on the number of tasks in a service that are allowed in the `RUNNING` or `PENDING` state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the `DRAINING` state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.

If a service is using either the `CODE_DEPLOY` or `EXTERNAL` deployment controller types and tasks that use the EC2 launch type, the **minimum healthy percent** and **maximum percent** values are used only to define the lower and upper limit on the number of the tasks in the service that remain in the `RUNNING` state while the container instances are in the `DRAINING` state. If the tasks in the service use the Fargate launch type, the minimum healthy percent and maximum percent values aren't used, although they're currently visible when describing your service.

When creating a service that uses the `EXTERNAL` deployment controller, you can specify only parameters that aren't controlled at the task set level. The only required parameter is the service name. You control your services using the CreateTaskSet operation. For more information, see [Amazon ECS Deployment Types](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-types.html) in the _Amazon Elastic Container Service Developer Guide_.

When the service scheduler launches new tasks, it determines task placement in your cluster using the following logic:

- Determine which of the container instances in your cluster can support your service's task definition (for example, they have the required CPU, memory, ports, and container instance attributes).

- By default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy) with the `placementStrategy` parameter):

  - Sort the valid container instances, giving priority to instances that have the fewest number of running tasks for this service in their respective Availability Zone. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement.

  - Place the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service.>

  take x-amz-target
    like native-string
  take create-service-request, like create-service-request

  line </#X-Amz-Target=AmazonEC2ContainerServiceV20141113.CreateService>

  hint <X-Amz-Target>, loan x-amz-target

  seed json, loan create-service-request

  loot 200
    seed json, like create-service-response
    note <Success>
  loot 480
    seed json, like server-exception
    note <ServerException>
  loot 481
    seed json, like client-exception
    note <ClientException>
  loot 482
    seed json, like invalid-parameter-exception
    note <InvalidParameterException>
  loot 483
    seed json, like cluster-not-found-exception
    note <ClusterNotFoundException>
  loot 484
    seed json, like unsupported-feature-exception
    note <UnsupportedFeatureException>
  loot 485
    seed json, like platform-unknown-exception
    note <PlatformUnknownException>
  loot 486
    seed json, like platform-task-definition-incompatibility-exception
    note <PlatformTaskDefinitionIncompatibilityException>
  loot 487
    seed json, like access-denied-exception
    note <AccessDeniedException>