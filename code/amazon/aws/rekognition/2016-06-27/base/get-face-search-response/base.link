
load @termsurf/snow/amazonaws.com/rekognition/2016-06-27/base/pagination-token
  take form pagination-token

load @termsurf/snow/amazonaws.com/rekognition/2016-06-27/base/person-matches
  take form person-matches

load @termsurf/snow/amazonaws.com/rekognition/2016-06-27/base/status-message
  take form status-message

load @termsurf/snow/amazonaws.com/rekognition/2016-06-27/base/video-job-status
  take form video-job-status

load @termsurf/snow/amazonaws.com/rekognition/2016-06-27/base/video-metadata
  take form video-metadata

form get-face-search-response, name <GetFaceSearchResponse>
  take job-status, name <JobStatus>
    like video-job-status
    void take
    note <The current status of the face search job.>
  take status-message, name <StatusMessage>
    like status-message
    void take
    note <If the job fails, `StatusMessage` provides a descriptive error message.>
  take next-token, name <NextToken>
    like pagination-token
    void take
    note <If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of search results.>
  take video-metadata, name <VideoMetadata>
    like video-metadata
    void take
    note <Information about a video that Amazon Rekognition analyzed. `Videometadata` is returned in every page of paginated responses from a Amazon Rekognition Video operation.>
  take persons, name <Persons>
    like person-matches
    void take
    note <An array of persons, PersonMatch, in the video whose face(s) match the face(s) in an Amazon Rekognition collection. It also includes time information for when persons are matched in the video. You specify the input collection in an initial call to `StartFaceSearch`. Each `Persons` element includes a time the person was matched, face match details (`FaceMatches`) for matching faces in the collection, and person information (`Person`) for the matched person.>