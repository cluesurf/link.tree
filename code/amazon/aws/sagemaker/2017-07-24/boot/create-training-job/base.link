
load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/create-training-job-response
  take form create-training-job-response

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/resource-in-use
  take form resource-in-use

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/resource-limit-exceeded
  take form resource-limit-exceeded

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/resource-not-found
  take form resource-not-found

load @textsurf/snow/base/native-string
  take form native-string

boot create-training-job, name <CreateTrainingJob>
  deed post
  note <Starts a model training job. After training completes, Amazon SageMaker saves the resulting model artifacts to an Amazon S3 location that you specify.

If you choose to host your model using Amazon SageMaker hosting services, you can use the resulting model artifacts as part of the model. You can also use the artifacts in a machine learning service other than Amazon SageMaker, provided that you know how to use them for inference.

In the request body, you provide the following:

- `AlgorithmSpecification` - Identifies the training algorithm to use.

- `HyperParameters` - Specify these algorithm-specific parameters to enable the estimation of model parameters during training. Hyperparameters can be tuned to optimize this learning process. For a list of hyperparameters for each training algorithm provided by Amazon SageMaker, see [Algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).

- `InputDataConfig` - Describes the training dataset and the Amazon S3, EFS, or FSx location where it is stored.

- `OutputDataConfig` - Identifies the Amazon S3 bucket where you want Amazon SageMaker to save the results of model training.

- `ResourceConfig` - Identifies the resources, ML compute instances, and ML storage volumes to deploy for model training. In distributed training, you specify more than one instance.

- `EnableManagedSpotTraining` - Optimize the cost of training machine learning models by up to 80% by using Amazon EC2 Spot instances. For more information, see [Managed Spot Training](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html).

- `RoleArn` - The Amazon Resource Name (ARN) that Amazon SageMaker assumes to perform tasks on your behalf during model training. You must grant this role the necessary permissions so that Amazon SageMaker can successfully complete model training.

- `StoppingCondition` - To help cap training costs, use `MaxRuntimeInSeconds` to set a time limit for training. Use `MaxWaitTimeInSeconds` to specify how long a managed spot training job has to complete.

- `Environment` - The environment variables to set in the Docker container.

- `RetryStrategy` - The number of times to retry the job when the job fails due to an `InternalServerError`.

For more information about Amazon SageMaker, see [How It Works](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works.html).>

  take x-amz-target
    like native-string
  take create-training-job-request, like create-training-job-request

  line </#X-Amz-Target=SageMaker.CreateTrainingJob>

  hint <X-Amz-Target>, loan x-amz-target

  seed json, loan create-training-job-request

  loot 200
    seed json, like create-training-job-response
    note <Success>
  loot 480
    seed json, like resource-in-use
    note <ResourceInUse>
  loot 481
    seed json, like resource-limit-exceeded
    note <ResourceLimitExceeded>
  loot 482
    seed json, like resource-not-found
    note <ResourceNotFound>
