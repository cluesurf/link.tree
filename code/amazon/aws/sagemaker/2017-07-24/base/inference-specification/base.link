
load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/content-types
  take form content-types

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/model-package-container-definition-list
  take form model-package-container-definition-list

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/realtime-inference-instance-types
  take form realtime-inference-instance-types

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/response-mime-types
  take form response-mime-types

load @textsurf/snow/amazonaws.com/sagemaker/2017-07-24/base/transform-instance-types
  take form transform-instance-types

form inference-specification, name <InferenceSpecification>
  note <Defines how to perform inference generation after a training job is run.>
  take containers, name <Containers>
    like model-package-container-definition-list
    note <The Amazon ECR registry path of the Docker image that contains the inference code.>
  take supported-transform-instance-types, name <SupportedTransformInstanceTypes>
    like transform-instance-types
    void take
    note <A list of the instance types on which a transformation job can be run or on which an endpoint can be deployed.

This parameter is required for unversioned models, and optional for versioned models.>
  take supported-realtime-inference-instance-types, name <SupportedRealtimeInferenceInstanceTypes>
    like realtime-inference-instance-types
    void take
    note <A list of the instance types that are used to generate inferences in real-time.

This parameter is required for unversioned models, and optional for versioned models.>
  take supported-content-types, name <SupportedContentTypes>
    like content-types
    note <The supported MIME types for the input data.>
  take supported-response-mime-types, name <SupportedResponseMIMETypes>
    like response-mime-types
    note <The supported MIME types for the output data.>
