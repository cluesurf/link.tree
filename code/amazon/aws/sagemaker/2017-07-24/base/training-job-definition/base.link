
load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/hyper-parameters
  take form hyper-parameters

load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/input-data-config
  take form input-data-config

load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/output-data-config
  take form output-data-config

load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/resource-config
  take form resource-config

load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/stopping-condition
  take form stopping-condition

load @tunebond/snow/amazonaws.com/sagemaker/2017-07-24/base/training-input-mode
  take form training-input-mode

form training-job-definition, name <TrainingJobDefinition>
  note <Defines the input needed to run a training job using the algorithm.>
  take training-input-mode, name <TrainingInputMode>
    like training-input-mode
    note <The input mode used by the algorithm for the training job. For the input modes that Amazon SageMaker algorithms support, see [Algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).

If an algorithm supports the `File` input mode, Amazon SageMaker downloads the training data from S3 to the provisioned ML storage Volume, and mounts the directory to docker volume for training container. If an algorithm supports the `Pipe` input mode, Amazon SageMaker streams data directly from S3 to the container.>
  take hyper-parameters, name <HyperParameters>
    like hyper-parameters
    void take
    note <The hyperparameters used for the training job.>
  take input-data-config, name <InputDataConfig>
    like input-data-config
    note <An array of `Channel` objects, each of which specifies an input source.>
  take output-data-config, name <OutputDataConfig>
    like output-data-config
    note <the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker creates subfolders for the artifacts.>
  take resource-config, name <ResourceConfig>
    like resource-config
    note <The resources, including the ML compute instances and ML storage volumes, to use for model training.>
  take stopping-condition, name <StoppingCondition>
    like stopping-condition
    note <Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, Amazon SageMaker ends the training job. Use this API to cap model training costs.

To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.>
