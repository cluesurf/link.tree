
load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/bounded-length-string
  take form bounded-length-string

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/inference-execution-status
  take form inference-execution-status

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/inference-input-configuration
  take form inference-input-configuration

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/inference-output-configuration
  take form inference-output-configuration

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/inference-scheduler-arn
  take form inference-scheduler-arn

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/inference-scheduler-name
  take form inference-scheduler-name

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/model-arn
  take form model-arn

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/model-name
  take form model-name

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/s3-object
  take form s3-object

load @drumwork/snow/amazonaws.com/lookoutequipment/2020-12-15/base/timestamp
  take form timestamp

form inference-execution-summary, name <InferenceExecutionSummary>
  note <Contains information about the specific inference execution, including input and output data configuration, inference scheduling information, status, and so on.>
  take model-name, name <ModelName>
    like model-name
    void take
    note <The name of the ML model being used for the inference execution.>
  take model-arn, name <ModelArn>
    like model-arn
    void take
    note <The Amazon Resource Name (ARN) of the ML model used for the inference execution.>
  take inference-scheduler-name, name <InferenceSchedulerName>
    like inference-scheduler-name
    void take
    note <The name of the inference scheduler being used for the inference execution.>
  take inference-scheduler-arn, name <InferenceSchedulerArn>
    like inference-scheduler-arn
    void take
    note <The Amazon Resource Name (ARN) of the inference scheduler being used for the inference execution.>
  take scheduled-start-time, name <ScheduledStartTime>
    like timestamp
    void take
    note <Indicates the start time at which the inference scheduler began the specific inference execution.>
  take data-start-time, name <DataStartTime>
    like timestamp
    void take
    note <Indicates the time reference in the dataset at which the inference execution began.>
  take data-end-time, name <DataEndTime>
    like timestamp
    void take
    note <Indicates the time reference in the dataset at which the inference execution stopped.>
  take data-input-configuration, name <DataInputConfiguration>
    like inference-input-configuration
    void take
    note <Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.>
  take data-output-configuration, name <DataOutputConfiguration>
    like inference-output-configuration
    void take
    note <Specifies configuration information for the output results from for the inference execution, including the output S3 location.>
  take customer-result-object, name <CustomerResultObject>
    like s3-object
    void take
  take status, name <Status>
    like inference-execution-status
    void take
    note <Indicates the status of the inference execution.>
  take failed-reason, name <FailedReason>
    like bounded-length-string
    void take
    note <Specifies the reason for failure when an inference execution has failed.>