
load @textsurf/snow/base/native-string
  take form native-string

load @textsurf/snow/googleapis.com/automl/v1beta1/base/operation
  take form operation

boot automl-projects-locations-models-batch-predict, name <automl.projects.locations.models.batchPredict>
  deed post
  note <Perform a batch prediction. Unlike the online Predict, batch prediction result won't be immediately available in the response. Instead, a long running operation object is returned. User can poll the operation result via GetOperation method. Once the operation is done, BatchPredictResult is returned in the response field. Available for following ML problems: * Image Classification * Image Object Detection * Video Classification * Video Object Tracking * Text Extraction * Tables>

  take name
    like native-string
    note <Required. Name of the model requested to serve the batch prediction.>
  take batch-predict-request, like batch-predict-request
    void take

  line </v1beta1/{name}:batchPredict>

  seed json, loan batch-predict-request

  loot 200
    seed json, like operation
    note <Successful response>